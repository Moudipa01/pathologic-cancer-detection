{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "812221f6046eb6002d9835e040d8d50675c4718e"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob \n",
    "from skimage.io import imread \n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "!pip install livelossplot\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cada1e5e63e66eaccab61c40422b7d7f8fc481c6"
   },
   "outputs": [],
   "source": [
    "# Output files\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
    "MODEL_PLOT_FILE = \"model_plot.png\"\n",
    "MODEL_FILE = \"model.h5\"\n",
    "TRAINING_PLOT_FILE = \"training.png\"\n",
    "VALIDATION_PLOT_FILE = \"validation.png\"\n",
    "ROC_PLOT_FILE = \"roc.png\"\n",
    "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b8d7a9899440da705f78f32d5c7a94c9b5434fb"
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "SAMPLE_COUNT = 85000\n",
    "TRAINING_RATIO = 0.9\n",
    "IMAGE_SIZE = 96\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 192\n",
    "VERBOSITY = 1\n",
    "TESTING_BATCH_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Data (https://www.kaggle.com/c/histopathologic-cancer-detection/data)\n",
    "#input_dir = '../input/'\n",
    "input_dir = '/Users/grzegorzsurma/Datasets/cancer_cells/'\n",
    "training_dir = input_dir + 'train/'\n",
    "data_frame = pd.DataFrame({'path': glob(os.path.join(training_dir,'*.tif'))})\n",
    "data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[6].split('.')[0])\n",
    "labels = pd.read_csv(input_dir + 'train_labels.csv')\n",
    "data_frame = data_frame.merge(labels, on='id')\n",
    "negatives = data_frame[data_frame.label == 0].sample(SAMPLE_COUNT)\n",
    "positives = data_frame[data_frame.label == 1].sample(SAMPLE_COUNT)\n",
    "data_frame = pd.concat([negatives, positives]).reset_index()\n",
    "data_frame = data_frame[['path', 'id', 'label']]\n",
    "data_frame['image'] = data_frame['path'].map(imread)\n",
    "\n",
    "training_path = '../training'\n",
    "validation_path = '../validation'\n",
    "\n",
    "for folder in [training_path, validation_path]:\n",
    "    for subfolder in ['0', '1']:\n",
    "        path = os.path.join(folder, subfolder)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "training, validation = train_test_split(data_frame, train_size=TRAINING_RATIO, stratify=data_frame['label'])\n",
    "\n",
    "data_frame.set_index('id', inplace=True)\n",
    "\n",
    "for images_and_path in [(training, training_path), (validation, validation_path)]:\n",
    "    images = images_and_path[0]\n",
    "    path = images_and_path[1]\n",
    "    for image in images['id'].values:\n",
    "        file_name = image + '.tif'\n",
    "        label = str(data_frame.loc[image,'label'])\n",
    "        destination = os.path.join(path, label, file_name)\n",
    "        if not os.path.exists(destination):\n",
    "            source = os.path.join(input_dir + 'train', file_name)\n",
    "            shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cec14fe7a59727d5606263f17aeff81699d912e0"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "training_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             rotation_range=180,\n",
    "                                             zoom_range=0.4, \n",
    "                                             width_shift_range=0.3,\n",
    "                                             height_shift_range=0.3,\n",
    "                                             shear_range=0.3,\n",
    "                                             channel_shift_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccad1f37cc2bfae0ba735b0b8e1ddb20a5930dae"
   },
   "outputs": [],
   "source": [
    "# Data generation\n",
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                 target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 class_mode='binary')\n",
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                              target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                              batch_size=BATCH_SIZE,\n",
    "                                                                              class_mode='binary')\n",
    "testing_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                           target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                           batch_size=BATCH_SIZE,\n",
    "                                                                           class_mode='binary',\n",
    "                                                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1dd6a67856557351a02e4ebcfc87e1c94c7706dc"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "xception = Xception(include_top=False, input_shape=input_shape)(inputs)\n",
    "nas_net = NASNetMobile(include_top=False, input_shape=input_shape)(inputs)\n",
    "\n",
    "outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), GlobalAveragePooling2D()(nas_net)])\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model,\n",
    "           to_file=MODEL_PLOT_FILE,\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a854c31ea90b6dada058e8048cc20a0a5907357",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Training\n",
    "history = model.fit_generator(training_generator,\n",
    "                              steps_per_epoch=len(training_generator), \n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=len(validation_generator),\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=VERBOSITY,\n",
    "                              callbacks=[PlotLossesKeras(),\n",
    "                                         ModelCheckpoint(MODEL_FILE,\n",
    "                                                         monitor='val_acc',\n",
    "                                                         verbose=VERBOSITY,\n",
    "                                                         save_best_only=True,\n",
    "                                                         mode='max'),\n",
    "                                         CSVLogger(TRAINING_LOGS_FILE,\n",
    "                                                   append=False,\n",
    "                                                   separator=';')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd1582290e369f0f6bed6c6856a1c850b6ec3ef4"
   },
   "outputs": [],
   "source": [
    "# Training plots\n",
    "epochs = [i for i in range(1, len(history.history['loss'])+1)]\n",
    "\n",
    "plt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\n",
    "plt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.title('training')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(TRAINING_PLOT_FILE, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\n",
    "plt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title('validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(VALIDATION_PLOT_FILE, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d366ba6530d8d2ae88f9a2947abb38c15e040a3"
   },
   "outputs": [],
   "source": [
    "# ROC testing plot\n",
    "model.load_weights(MODEL_FILE)\n",
    "predictions = model.predict_generator(testing_generator, steps=len(testing_generator), verbose=VERBOSITY)\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(testing_generator.classes, predictions)\n",
    "area_under_curve = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bed9d9a9b3942bb97c4f33c94dbb54501c7f5cbc"
   },
   "outputs": [],
   "source": [
    "# Kaggle testing\n",
    "testing_files = glob(os.path.join('../input/test/','*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "for index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n",
    "    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n",
    "    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    data_frame['image'] = data_frame['path'].map(imread)\n",
    "    images = np.stack(data_frame.image, axis=0)\n",
    "    predicted_labels = [model.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n",
    "    predictions = np.array(predicted_labels)\n",
    "    data_frame['label'] = predictions\n",
    "    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n",
    "submission.to_csv(KAGGLE_SUBMISSION_FILE, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
